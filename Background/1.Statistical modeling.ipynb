{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical model \n",
    "\n",
    "A statistical model will be a mathematical structure used to imitate and approximate, the data generating process. It typically describes relationships among variables while accounting for uncertainty and variability in the data. \n",
    "\n",
    "## Modelling objectives\n",
    "1. **Quantify uncertainty** - Tackled with theory of probability\n",
    "\n",
    "2. **Inference** - What is the behavior of the whole population\n",
    "\n",
    "3. **Measure support for hypothesis** - Is this strong enough evidence to support or validate the experts claim? \n",
    "\n",
    "4. **Prediction** \n",
    "\n",
    "## Statisticam modelling process\n",
    "\n",
    "1. Understand the problem\n",
    "\n",
    "2. Plan and collect data\n",
    "\n",
    "3. Explore the data\n",
    "\n",
    "4. Postulate model (choose the model)\n",
    "\n",
    "5. Fit model\n",
    "\n",
    "6. Check the model \n",
    "\n",
    "7. Iterate (steps: 4-6)\n",
    "\n",
    "8. Use the model \n",
    "\n",
    "## Questions \n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Which objective of statistical modeling is best illustrated by the following example?\n",
    "\n",
    "You fit a linear regression of monthly stock values for your company. You use the estimates and recent stock history to calculate a forecast of the stock's value for the next three months.\n",
    "\n",
    "a. Quantify uncertainty\n",
    "\n",
    "b. Inference\n",
    "\n",
    "c. Hypothesis testing\n",
    "\n",
    "d. Prediction\n",
    "\n",
    "**Answer 1**\n",
    "\n",
    "d.\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "Which objective of statistical modeling is best illustrated by the following example?\n",
    "\n",
    "A biologist proposes a treatment to decrease genetic variation in plant size. She conducts an experiment and asks you (the statistician) to analyze the data to conclude whether a 10% decrease in variation has occurred.\n",
    "\n",
    "a. Quantify uncertainty\n",
    "\n",
    "b. Inference\n",
    "\n",
    "c. Hypothesis testing\n",
    "\n",
    "d. Prediction\n",
    "\n",
    "**Answer 2**\n",
    "\n",
    "c.\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "Which objective of statistical modeling is best illustrated by the following example?\n",
    "\n",
    "The same biologist form the previous question asks you how many experiments would be necessary to have a 95% chance at detecting a 10% decrease in plant variation.\n",
    "\n",
    "a. Quantify uncertainty\n",
    "\n",
    "b. Inference\n",
    "\n",
    "c. Hypothesis testing\n",
    "\n",
    "d. Prediction\n",
    "\n",
    "**Answer 3**\n",
    "\n",
    "a.\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "Which of the following scenarios best illustrates the statistical modeling objective of inference?\n",
    "\n",
    "a. A model inputs academic performance of 1000 students and predicts which student will be valedictorian after another year of school.\n",
    "\n",
    "b. A social scientist collects data and detects positive correlation between sleep deprivation and traffic accidents.\n",
    "\n",
    "c. A natural language processing algorithm analyzes the first four words of a sentence and provides words to complete the sentence.\n",
    "\n",
    "d. A venture capitalist uses data about several companies to build a model and makes recommendations about which company to invest in next based on growth forecasts.\n",
    "\n",
    "\n",
    "**Answer 4**\n",
    "\n",
    "b\n",
    "\n",
    "**Question 5**\n",
    "\n",
    "Which step in the statistical modeling cycle was not followed in the following scenario?\n",
    "\n",
    "Susan gathers data recording heights of children and fits a linear regression predicting height from age. To her surprise, the model does not predict well the heights for ages 14-17 (because the growth rate changes with age), both for children included in the original data as well as other children outside the model training data.\n",
    "\n",
    "a. Use the model\n",
    "\n",
    "b. Explore the data\n",
    "\n",
    "c. Plan and properly collect relevant data\n",
    "\n",
    "d. Fit the model\n",
    "\n",
    "**Answer 5**\n",
    "\n",
    "b\n",
    "\n",
    "**Question 6**\n",
    "\n",
    "Which of the following is a possible consequence of failure to plan and properly collect relevant data?\n",
    "\n",
    "a. You will not produce enough data to make conclusions with a sufficient degree of confidence.\n",
    "\n",
    "b. Your selected model will not be able to fit the data.\n",
    "\n",
    "c. You may not be able to visually explore the data.\n",
    "\n",
    "d. Your analysis may produce incomplete or misleading results.\n",
    "\n",
    "**Answer 6**\n",
    "\n",
    "d.\n",
    "\n",
    "\n",
    "Xie operates a bakery and wants to use a statistical model to determine how many loaves of bread he should bake each day in preparation for weekday lunch hours. He decides to fit a Poisson model to count the demand for bread. He selects two weeks which have typical business, and for those two weeks, counts how many loaves are sold during the lunch hour each day. He fits the model, which estimates that the daily demand averages 22.3 loaves.\n",
    "\n",
    "Over the next month, Xie bakes 23 loaves each day, but is disappointed to find that on most days he has excess bread and on a few days (usually Mondays), he runs out of loaves early.\n",
    "\n",
    "**Question 7**\n",
    "\n",
    "Which of the following steps of the modeling process did Xie skip?\n",
    "\n",
    "a. Understand the problem\n",
    "\n",
    "b. Postulate a model\n",
    "\n",
    "c. Fit the model\n",
    "\n",
    "d. Check the model and iterate\n",
    "\n",
    "e. Use the model\n",
    "\n",
    "**Answer 7**\n",
    "\n",
    "c\n",
    "\n",
    "**Question 8**\n",
    "\n",
    "What might you recommend Xie do next to fix this omission and improve his predictive performance?\n",
    "\n",
    "a. Abandon his statistical modeling initiative.\n",
    "\n",
    "b. Collect three more weeks of data from his bakery and other bakeries throughout the city. Re-fit the same model to the extra data and follow the results based on more data.\n",
    "\n",
    "c. Plot daily demand and model predictions against the day of the week to check for patterns that may account for the extra variability. Fit and check a new model which accounts for this.\n",
    "\n",
    "d. Trust the current model and continue to produce 23 loaves daily, since in the long-run average, his error is zero.\n",
    "\n",
    "**Answer 8**\n",
    "\n",
    "c\n",
    "\n",
    "# Bayesian Modeling\n",
    "\n",
    "## Components of Bayesian Models\n",
    "\n",
    "Let:\n",
    "\n",
    "heights $n = 15$ men\n",
    "$$y_{i} = \\mu + \\epsilon_{i} \\text{, } \\epsilon_{i} \\stackrel{iid}{\\sim} N(0, \\sigma^{2}), i = 1, ..., n$$\n",
    "$$ y_{i} \\stackrel{iid}{\\sim} N(\\mu, \\sigma^{2})$$\n",
    "\n",
    "So far, this model is the same for frequentists and Bayesians. \n",
    "\n",
    "The frequentist approach to fitting this model right here. Would be to consider $\\mu$ and $\\sigma$ to be fixed but unknown constants, and then we would estimate them. To calculate our uncertainty in those estimates. A frequentist approach would consider how much the estimates of $\\mu$ and $\\sigma$ might change. If we were to repeat the sampling process and obtain another sample of 15 men, over, and over.\n",
    "\n",
    "The Bayesian approach, the one we're going to take here. Tackles our uncertainty in $\\mu$ and $\\sigma^{2}$ with probability directly. By treating them as random variables with their own probability distributions. \n",
    "\n",
    "The three primary components of Bayesian models that we often work with are:\n",
    "\n",
    "1) **likelihood** ($p(y|\\theta)$)\n",
    "\n",
    "2) **prior** ($p(\\theta)$the probability distribution that characterizes our uncertainty with the parameter $\\theta$.)\n",
    "\n",
    "3) **posterior** ($p(\\theta|y) = \\dfrac{p(\\theta, y)}{p(y)} = \\dfrac{p(\\theta, y)}{\\int p(\\theta, y)d\\theta} = \\dfrac{p(y |\\theta)p(\\theta)}{\\int p(y |\\theta)p(\\theta) d\\theta}$).\n",
    "\n",
    "\n",
    "## Model Specification\n",
    "\n",
    "Before fitting any model we first need to specify all of its components. One convenient way to do this is to write down the hierarchical form of the model. By hierarchy, we mean that the model is specified in steps or in layers. \n",
    "\n",
    "**$1^{rst}$ level  - likelihood**\n",
    "\n",
    "$$ y_{i}|\\mu, \\sigma^{2} \\stackrel{iid}{\\sim} N(\\mu, \\sigma^{2}) i = i, ..., n$$\n",
    "\n",
    "** $2^{nd}$ level - the prior distribution from $\\mu$ and $\\sigma^{2}$ **\n",
    "\n",
    "$$P(\\mu, \\sigma^{2}) = p(\\mu)p(\\sigma^{2})$$\n",
    "For now we're going to say that they're independent priors. We can assume independents in the prior and still get dependents in the posterior distribution. \n",
    "\n",
    "The conjugate prior for mu, if we know the value of $\\sigma^{2}$, is a normal distribution, and the conjugate prior for $\\sigma^{2}$ when $\\mu$ is known is the inverse gamma distribution. \n",
    "\n",
    "** $3^{rd}$ level - Prior distribution for $\\mu$ and $\\sigma^{2}$**\n",
    "\n",
    "$$ \\mu \\sim N(\\mu_{0}, \\sigma^{2}_{0})$$\n",
    "$$ \\sigma^{2} \\sim IG(\\nu, \\beta_{0})$$\n",
    "\n",
    "A useful way to write the model is as a graphical representation which illustrates the dependences among the parameters. \n",
    "\n",
    "\n",
    "We start from the priors ($\\mu$ and $\\sigma^2$) and finish with the likelihood. We denote the random variables that follow their own distribution by a single cycle and the observed values as a double cycle. The square denotes that the y's come from the same distribution across all values of i. \n",
    "\n",
    "<img src=\"graphical_model.png\">\n",
    "\n",
    "## Posterior derivation\n",
    "\n",
    "So far, we've only drawn the model with two levels. But in reality, there's nothing that'll stop us from adding more layers. Let's go through the previous example and illustrate it as an hierchical model.  One reason we might do this is if the data are hierarchically organized so that the observations are naturally grouped together. \n",
    "\n",
    "$$ y_{i}|\\mu, \\sigma^{2} \\stackrel{iid}{\\sim} N(\\mu, \\sigma^{2}) i = i, ..., n$$\n",
    "$$ \\mu| \\sigma^{2} \\sim N(\\mu_{0}, \\dfrac{\\sigma^{2}}{w_{0}})$$\n",
    "$$ \\sigma^{2} \\sim IG(\\nu, \\beta_{0})$$\n",
    "\n",
    "This can be illustrated as : \n",
    "\n",
    "<img src=\"hierarchical_graphical_model.png\">\n",
    "\n",
    "Once we have a model specification, we can write out what the full posterior distribution for all the parameters given the data looks like. \n",
    "\n",
    "Remember that the numerator in Bayes' theorem is the joint distribution of all random quantities, all the nodes in this graphical representation over here from all of the layers. So for this model that we have right here, we have a joint distribution that'll look like this:\n",
    "\n",
    "$$P(y_{1},....,y_{n},\\mu, \\sigma^{2}) = P(y_{1},....,y_{n}|\\mu, \\sigma^{2})p(\\mu|\\sigma^{2})p(\\sigma^{2}) $$\n",
    "$$ = \\prod_{i = 1}^{n}[N(y_{i}|\\mu, \\sigma^{2})] \\times N(\\mu|\\mu_{0}, \\dfrac{\\sigma^{2}}{w_{0}})\\times IG(\\sigma^{2}|\\nu_{0}, \\beta_{0})$$\n",
    "$$\\propto p(\\mu,\\sigma^{2}|y_{1},....,y_{n})$$\n",
    "$$\\text{Please note that the distribution abbreviation stands for the density function}$$\n",
    "\n",
    "$$\\text{But how did we derive that the  joint distribution of everything is proportional to the}$$ \n",
    "$$\\text{posterior distribution of $\\mu$ and $\\sigma^{2}$, given all of the data?}$$\n",
    "\n",
    "$$\\text{Remember that:}$$\n",
    "$$p(\\theta|y) = \\dfrac{p(y|\\theta)p(\\theta)}{\\int p(y|\\theta)p(\\theta)d\\theta}$$\n",
    "$$\\propto p(y|\\theta)p(\\theta)$$ \n",
    "\n",
    "$$\\text{since $\\int p(y|\\theta)p(\\theta)d\\theta$ is constant}$$\n",
    "\n",
    "The only thing missing in this expression right here is just some constant number that causes the expression to integrate to 1. If we can recognize this expression as being proportional to a common distribution, then our work is done, and we know what our posterior distribution is. \n",
    "\n",
    "If we do not use conjugate priors or if the models are more complicated, then the posterior distribution will not have a standard form that we can recognize. \n",
    "\n",
    "## Non-conjugate models\n",
    "\n",
    "Let's go over a couple examples of models that don't have clean posterior distributions. \n",
    "\n",
    "** Example 1**\n",
    "\n",
    "Suppose we have values that represent the percentage change in total personnel from last year to this year for, we'll say, ten companies. \n",
    "\n",
    "These companies come from a particular industry. We're going to assume for now:\n",
    "\n",
    "$$y_{i}|\\mu  \\stackrel{iid}{\\sim} N(\\mu, 1) \\text{nknown mean could represent growth for this particular industry}$$\n",
    "$$\\text{Let: } \\mu \\sim  t(0,1,1) $$ \n",
    "\n",
    "Recall that the posterior distribution of mu is proportional to the likelihood times the prior. Let's write the expression for that in this model. \n",
    "\n",
    "$$P(\\mu|y_{1},...,y_{n}) \\propto \\prod_{i = 1}^{n}[\\dfrac{1}{\\sqrt{2\\pi}}exp(-\\tfrac{1}{2}(y_{i}-\\mu)^{2})]\\dfrac{1}{\\pi(1 + \\mu^{2})} $$ $$\\propto exp[-\\dfrac{1}{2}\\sum_{i=1}^{n}(y_{i}-\\mu)^{2}]\\dfrac{1}{1+\\mu^{2}}$$ \n",
    "$$\\propto exp[-\\dfrac{1}{2}(\\sum_{i=1}^{n}y_{i}^{2} - 2\\mu\\sum_{i=1}^{n}y_{i} + n\\mu^{2}]\\dfrac{1}{1+\\mu^{2}}$$ \n",
    "\n",
    "$$\\propto \\dfrac{exp[n(\\bar{y}\\mu - \\dfrac{\\mu^{2}}{2})]}{1+\\mu^{2}}$$\n",
    "\n",
    "**Example 2**\n",
    "\n",
    "$$ y_{i}|\\mu, \\sigma^{2} \\stackrel{iid}{\\sim} N(\\mu, \\sigma^{2}) i = i, ..., n$$\n",
    "$$ \\mu| \\sigma^{2} \\sim N(\\mu_{0}, \\sigma_{0}^{2})$$\n",
    "$$ \\sigma^{2} \\sim IG(\\nu, \\beta_{0})$$\n",
    "\n",
    "We saw earlier that if you include sigma squared in the prior for mu, and use the hierarchical model that we presented earlier, that model would be conjugate and have a closed form solution. \n",
    "\n",
    "However, in the more general case that we have right here, the posterior distribution does not appear as a distribution that we can simulate or integrate. Challenging posterior distributions like these ones and most others that we'll encounter later on kept Bayesian in methods from entering the main stream of statistics for many years. Since only the simplest problems were tractable.\n",
    "\n",
    "However, computational methods invented in the 1950's, and implemented by statisticians decades later, revolutionized the field. \n",
    "We do have the ability to simulate from the posterior distributions in this lesson as well as for many other more complicated models. \n",
    "\n",
    "\n",
    "**What is the major challenge do we face with both of the models introduced in this segment?**\n",
    "\n",
    "We have the posterior distribution up to a normalizing constant, but we are unable to integrate it to obtain important quantities, such as the posterior mean or probability intervals. \n",
    "\n",
    "In low dimensional problems with only a few parameters we can resort to numerical methods for integration, but this solution only works for a narrow set of models.\n",
    "\n",
    "## Questions\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Which of the following is one major difference between the frequentist and Bayesian approach to modeling data?\n",
    "\n",
    "a. The frequentist paradigm treats the data as fixed while the Bayesian paradigm considers data to be random.\n",
    "\n",
    "b. Frequentists treat the unknown parameters as fixed (constant) while Bayesians treat unknown parameters as random variables.\n",
    "\n",
    "c. Frequentist models are deterministic (don't use probability) while Bayesian models are stochastic (based on probability).\n",
    "\n",
    "c. Frequentist models require a guess of parameter values to initialize models while Bayesian models require initial distributions for the parameters.\n",
    "\n",
    "**Answer 1**\n",
    "\n",
    "b.\n",
    "\n",
    "The only random variables in frequentist models are the data. The Bayesian paradigm also uses probability to describe one's uncertainty about unknown model parameters.\n",
    "\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "Suppose we have a statistical model with unknown parameter θ, and we assume a normal prior $θ∼N($\\mu_{0}$,\\sigma^{2})$, where $\\mu_{0}$ is the prior mean and $\\sigma^{2}$ is the prior variance. What does increasing $\\sigma^{2}$ say about our prior beliefs about θ?\n",
    "\n",
    "a. Increasing the variance of the prior narrows the range of what we think θ might be, indicating greater confidence in our prior mean guess $\\mu_{0}$.\n",
    "\n",
    "b. Increasing the variance of the prior narrows the range of what we think θ might be, indicating less confidence in our prior mean guess $\\mu_{0}$.\n",
    "\n",
    "c. Increasing the variance of the prior widens the range of what we think θ might be, indicating greater confidence in our prior mean guess $\\mu_{0}$.\n",
    "\n",
    "d. Increasing the variance of the prior widens the range of what we think θ might be, indicating less confidence in our prior mean guess $\\mu_{0}$.\n",
    "\n",
    "**Answer 2**\n",
    "\n",
    "d.\n",
    "\n",
    "This also lowers the \"effective sample size\" of the prior, so that the data become more influential in determining the posterior for θ.\n",
    "\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "We presented Bayes' theorem for the case where parameters are continuous. What is the correct expression for the posterior distribution of θ if it is discrete (takes on only specific values)?\n",
    "\n",
    "a. $p(θ∣y)= \\dfrac{p(y∣θ)⋅p(θ)}{∫p(y∣θ)⋅p(θ)dθ}$\n",
    "\n",
    "b. $p(θj∣y)=\\dfrac{p(y∣θj)⋅p(θj)}{∑jp(y∣θj)⋅p(θj)}$\n",
    "\n",
    "c. $p(θ)=∫p(θ∣y)⋅p(y)dy$\n",
    "\n",
    "d. $p(θ)=∑jp(θ∣yj)⋅p(yj)$\n",
    "\n",
    "**Answer 3**\n",
    "\n",
    "b.\n",
    "\n",
    "\n",
    "We have described Xie's model for predicting demand for bread at his bakery. During the lunch hour on a given day, the number of orders (the response variable) follows a Poisson distribution. All days have the same mean (expected number of orders). Xie is a Bayesian, so he selects a conjugate gamma prior for the mean with shape 3 and rate 1/15. He collects data on Monday through Friday for two weeks.\n",
    "\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "Which of the following hierarchical models represents this scenario?\n",
    "\n",
    "a.$ yi∣λ \\stackrel{iid}{\\sim} Pois(λ)$ for i=1,…,10, $λ \\sim Gamma(3,1/15)$ \n",
    "\n",
    "b. $ yi∣λ \\stackrel{iid}{\\sim} N(\\mu, 1.0^{2})$ for i=1,…,10, $\\mu \\sim N(3,15)$ \n",
    "\n",
    "c. $ yi∣λ \\stackrel{iid}{\\sim} Pois(λ)$  for i=1,…,10,$\\lambda| \n",
    "\\alpha \\sim Gamma(α,\\dfrac{1}{15})α\\sim Gamma(3.0,1.0)$\n",
    "\n",
    "d. $ yi∣λ \\stackrel{iid}{\\sim} Pois(λ)$  for i=1,…,10,$\\lambda| \n",
    "\\mu \\sim Gamma(\\mu,\\dfrac{1}{15})\\mu \\sim Gamma(3.0,1.0^{2})$\n",
    "\n",
    "**Answer 4**\n",
    "\n",
    "a.\n",
    "\n",
    "The likelihood is Poisson with the same mean for all observations, called λ here. The mean λ has a gamma prior.\n",
    "\n",
    "**Question 5**\n",
    "\n",
    "In a Bayesian model, let y denote all the data and θ denote all the parameters. Which of the following statements about the relationship between the joint distribution of all variables p(y,θ)=p(⋯) and the posterior distribution p(θ∣y) is true?\n",
    "\n",
    "a. They are actually equal to each other so that p(y,θ)=p(θ∣y).\n",
    "\n",
    "b. The joint distribution p(y,θ) is equal to the posterior distribution times a function f(θ) which contains the modification (update) of the prior.\n",
    "\n",
    "c. They are proportional to each other so that p(y,θ)=c⋅p(θ∣y) where c is a constant number that doesn't involve θ at all.\n",
    "\n",
    "d. Neither is sufficient alone--they are both necessary to make inferences about θ.\n",
    "\n",
    "**Answer 5**\n",
    "\n",
    "c. \n",
    "\n",
    "This fact allows us to work with the joint distribution p(y,θ) which is usually easier to compute. MCMC methods, which we will learn in the next module, only require us to know the posterior up to proportionality.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
